# Copy this file to .env and fill in your actual values
# Never commit .env to version control

# Google Gemini API Key - Get from https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your_api_key_here

# Gemini Model Selection (optional)
# OPTIONS: gemini-3-flash (faster, cheaper) | gemini-3-pro (better, slower, costlier)
GEMINI_MODEL=gemini-3-pro

# ReAct Pattern Configuration (optional)
# Max iterations for multi-step search and reasoning (default: 5)
# Higher values allow more search refinement but increase latency and cost
MAX_REACT_ITERATIONS=6

# Max retries for API errors (default: 2)
# How many times to retry failed LLM API calls before giving up
MAX_RETRIES=2

# Ingestion Pipeline Configuration (optional)
INGESTION_DATA_DIR=../data
INGESTION_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
INGESTION_TYPESENSE_HOST=localhost
INGESTION_TYPESENSE_PORT=8108
INGESTION_TYPESENSE_API_KEY=xyz
INGESTION_CHUNK_MAX_CHARS=500

# Vector Search Configuration (optional)
# Number of nearest neighbors for semantic/vector search (default: 100)
VECTOR_SEARCH_K=100

# Hybrid Search Configuration (optional)
# Weight balance for hybrid search (0.0=keyword only, 1.0=vector only, 0.5=equal, default: 0.5)
HYBRID_SEARCH_ALPHA=0.5

# Application Settings
LOG_LEVEL=INFO
DEBUG=false

